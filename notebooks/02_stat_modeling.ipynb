{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7064e66e",
   "metadata": {},
   "source": [
    "# Transaction Prediction Model\n",
    "\n",
    "This notebook focuses on building a predictive model for transaction counts per customer.\n",
    "\n",
    "## Approach\n",
    "- **Problem formulation**: Conditional count modeling (predicting number of transactions)\n",
    "- **Model**: GLM with Tweedie loss (1 < p < 2) as approximation to Negative Binomial\n",
    "- **Features**: Time-aware features (recency, frequency, rolling windows)\n",
    "- **Temporal splitting**: Strict time-based train/test splits to avoid leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42849b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded\n",
      "✓ Project root: /mnt/c/Users/zaido/OneDrive/Bureau/Quod_THA\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup: Add project root to Python path for imports\n",
    "# (Notebooks run from notebooks/ directory, so we need to add parent to path)\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import project configuration\n",
    "from src.config import (\n",
    "    PROJECT_ROOT,\n",
    "    FIGURES_DIR,\n",
    "    OUTPUTS_DIR,\n",
    "    ensure_directories\n",
    ")\n",
    "\n",
    "# Ensure directories exist\n",
    "ensure_directories()\n",
    "\n",
    "# Use config paths\n",
    "OUTPUTS = OUTPUTS_DIR\n",
    "FIGURES = FIGURES_DIR\n",
    "\n",
    "print(\"✓ Imports loaded\")\n",
    "print(f\"✓ Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d383102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw transaction data...\n",
      "Loaded 975,955 raw transactions\n",
      "Cleaning transaction data...\n",
      "Removed 676380 duplicate rows (kept first occurrence)\n",
      "Cleaned data: 299,575 transactions\n",
      "Saving processed data to /mnt/c/Users/zaido/OneDrive/Bureau/Quod_THA/data/processed/transactions_cleaned.csv\n",
      "Loaded 299,575 transactions\n",
      "Date range: 2017-01-01 00:00:00 to 2020-03-17 00:00:00\n",
      "Unique customers: 2,002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9447359</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435072</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5391951</td>\n",
       "      <td>Opel</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5391951</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1435072</td>\n",
       "      <td>Peugeot</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id       date\n",
       "0      9447359      Nissan 2017-01-01\n",
       "1      1435072        Fiat 2017-01-01\n",
       "2      5391951        Opel 2017-01-01\n",
       "3      5391951  Volkswagen 2017-01-01\n",
       "4      1435072     Peugeot 2017-01-01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load processed data\n",
    "from src.data import load_and_process_transactions\n",
    "import importlib, src.data as data\n",
    "importlib.reload(data)\n",
    "\n",
    "df = load_and_process_transactions(force_reprocess=True)\n",
    "\n",
    "print(f\"Loaded {len(df):,} transactions\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Unique customers: {df['customer_id'].nunique():,}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d383102",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Build time-aware features for customer $i$ at cutoff time $t$:\n",
    "\n",
    "- $N_i(t-1, t)$: Transactions in last 1 month\n",
    "- $N_i(t-3, t)$: Transactions in last 3 months\n",
    "- $N_i(t-6, t)$: Transactions in last 6 months\n",
    "- $N_i(t-3, t) - N_i(t-6, t-3)$: Change in transaction rate\n",
    "- `days_since_last_tx(i, t)`: Recency feature\n",
    "- `active_months(i, t)`: Number of active months\n",
    "- `month_of_year(t)`: Seasonal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1aa74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing feature engineering for customer 9447359 at 2019-01-31 00:00:00\n",
      "\n",
      "Feature vector:\n",
      "n_transactions_1m     11.0\n",
      "n_transactions_3m     46.0\n",
      "n_transactions_6m     74.0\n",
      "change_rate_3m        18.0\n",
      "days_since_last_tx     6.0\n",
      "active_months         25.0\n",
      "month_of_year          1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Functions\n",
    "\n",
    "def compute_transaction_counts(df, customer_id, cutoff_date, window_months):\n",
    "    \"\"\"Compute number of transactions for a customer in a time window.\"\"\"\n",
    "    # Ensure cutoff_date is pd.Timestamp (tz-naive)\n",
    "    cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    if cutoff_date.tz is not None:\n",
    "        cutoff_date = cutoff_date.tz_localize(None)\n",
    "    \n",
    "    # Calculate start date (months before cutoff)\n",
    "    start_date = cutoff_date - pd.DateOffset(months=window_months)\n",
    "    \n",
    "    # df['date'] is datetime64[ns] tz-naive from data.py, compare directly with Timestamp\n",
    "    mask = (\n",
    "        (df['customer_id'] == customer_id) &\n",
    "        (df['date'] >= start_date) &\n",
    "        (df['date'] < cutoff_date)\n",
    "    )\n",
    "    return mask.sum()\n",
    "\n",
    "\n",
    "def compute_days_since_last_transaction(df, customer_id, cutoff_date):\n",
    "    \"\"\"Compute days since last transaction for a customer.\"\"\"\n",
    "    # Ensure cutoff_date is pd.Timestamp (tz-naive)\n",
    "    cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    if cutoff_date.tz is not None:\n",
    "        cutoff_date = cutoff_date.tz_localize(None)\n",
    "    \n",
    "    # df['date'] is datetime64[ns] tz-naive from data.py, compare directly with Timestamp\n",
    "    customer_tx = df[df['customer_id'] == customer_id]\n",
    "    customer_tx_before = customer_tx[customer_tx['date'] < cutoff_date]\n",
    "    \n",
    "    if len(customer_tx_before) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    last_tx_date = pd.Timestamp(customer_tx_before['date'].max())\n",
    "    delta = (cutoff_date - last_tx_date).days\n",
    "    return float(delta)\n",
    "\n",
    "\n",
    "def compute_active_months(df, customer_id, cutoff_date):\n",
    "    \"\"\"\n",
    "    Compute number of months since customer's first transaction.\n",
    "    \n",
    "    Returns the number of months between the customer's first ever transaction\n",
    "    and the cutoff date.\n",
    "    \"\"\"\n",
    "    # Ensure cutoff_date is pd.Timestamp (tz-naive)\n",
    "    cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    if cutoff_date.tz is not None:\n",
    "        cutoff_date = cutoff_date.tz_localize(None)\n",
    "    \n",
    "    # df['date'] is datetime64[ns] tz-naive from data.py, compare directly with Timestamp\n",
    "    customer_tx = df[df['customer_id'] == customer_id]\n",
    "    customer_tx_before = customer_tx[customer_tx['date'] < cutoff_date]\n",
    "    \n",
    "    if len(customer_tx_before) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Find first transaction date (convert to Timestamp)\n",
    "    first_tx_date = pd.Timestamp(customer_tx_before['date'].min())\n",
    "    \n",
    "    # Calculate number of months between first transaction and cutoff\n",
    "    # Using year-month periods to count calendar months\n",
    "    first_period = pd.Period(first_tx_date, freq='M')\n",
    "    cutoff_period = pd.Period(cutoff_date, freq='M')\n",
    "    \n",
    "    # Number of months (inclusive of both first and cutoff month)\n",
    "    active_months = (cutoff_period - first_period).n + 1\n",
    "    \n",
    "    return active_months\n",
    "\n",
    "\n",
    "def create_feature_vector(df, customer_id, cutoff_date):\n",
    "    \"\"\"\n",
    "    Create feature vector for a customer at a cutoff time.\n",
    "    \n",
    "    Features:\n",
    "    - n_transactions_1m: N_i(t-1, t) - Transactions in last 1 month\n",
    "    - n_transactions_3m: N_i(t-3, t) - Transactions in last 3 months\n",
    "    - n_transactions_6m: N_i(t-6, t) - Transactions in last 6 months\n",
    "    - change_rate_3m: N_i(t-3, t) - N_i(t-6, t-3) - Change in transaction rate\n",
    "    - days_since_last_tx: Days since last transaction\n",
    "    - active_months: Number of months since customer's first transaction\n",
    "    - month_of_year: Month of cutoff date (1-12)\n",
    "    \"\"\"\n",
    "    # Transaction counts in different windows\n",
    "    n_1m = compute_transaction_counts(df, customer_id, cutoff_date, window_months=1)\n",
    "    n_3m = compute_transaction_counts(df, customer_id, cutoff_date, window_months=3)\n",
    "    n_6m = compute_transaction_counts(df, customer_id, cutoff_date, window_months=6)\n",
    "    \n",
    "    # Change in transaction rate: N(t-3, t) - N(t-6, t-3)\n",
    "    # This compares recent 3 months vs previous 3 months\n",
    "    t_minus_3 = cutoff_date - pd.DateOffset(months=3)\n",
    "    n_3m_prev = compute_transaction_counts(df, customer_id, t_minus_3, window_months=3)\n",
    "    change_rate = n_3m - n_3m_prev\n",
    "    \n",
    "    # Recency feature\n",
    "    days_since_last = compute_days_since_last_transaction(df, customer_id, cutoff_date)\n",
    "    \n",
    "    # Active months (months since first transaction)\n",
    "    active_months = compute_active_months(df, customer_id, cutoff_date)\n",
    "    \n",
    "    # Seasonal feature (cutoff_date is already pd.Timestamp)\n",
    "    month_of_year = cutoff_date.month\n",
    "    \n",
    "    # Create feature vector\n",
    "    features = pd.Series({\n",
    "        'n_transactions_1m': n_1m,\n",
    "        'n_transactions_3m': n_3m,\n",
    "        'n_transactions_6m': n_6m,\n",
    "        'change_rate_3m': change_rate,\n",
    "        'days_since_last_tx': days_since_last,\n",
    "        'active_months': active_months,\n",
    "        'month_of_year': month_of_year,\n",
    "    })\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def create_feature_matrix(df, cutoff_date, customer_ids=None):\n",
    "    \"\"\"\n",
    "    Create feature matrix for all customers (or specified customers) at a single cutoff date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Transaction dataframe with columns: customer_id, date, product_id\n",
    "    cutoff_date : pd.Timestamp or str\n",
    "        Single cutoff date for all customers (features computed using data before this date)\n",
    "    customer_ids : array-like, optional\n",
    "        If provided, only compute features for these customers. Otherwise, use all customers\n",
    "        that have at least one transaction before cutoff_date.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Feature matrix with columns: customer_id, cutoff_date, and feature columns.\n",
    "        Only includes customers with at least one transaction before cutoff_date.\n",
    "    \"\"\"\n",
    "    # Ensure cutoff_date is pd.Timestamp (tz-naive)\n",
    "    cutoff_date = pd.Timestamp(cutoff_date)\n",
    "    if cutoff_date.tz is not None:\n",
    "        cutoff_date = cutoff_date.tz_localize(None)\n",
    "    \n",
    "    # df['date'] is datetime64[ns] tz-naive from data.py, compare directly with Timestamp\n",
    "    # Filter transactions before cutoff\n",
    "    df_before_cutoff = df[df['date'] < cutoff_date].copy()\n",
    "    \n",
    "    # Get customers with at least one transaction before cutoff\n",
    "    customers_with_history = df_before_cutoff['customer_id'].unique()\n",
    "    \n",
    "    # If customer_ids provided, filter to intersection (customers with history AND in provided list)\n",
    "    if customer_ids is not None:\n",
    "        customer_ids = pd.Series(customer_ids).unique()\n",
    "        valid_customers = pd.Series([c for c in customer_ids if c in customers_with_history])\n",
    "        if len(valid_customers) == 0:\n",
    "            raise ValueError(\"No customers in provided list have purchase history before cutoff_date\")\n",
    "    else:\n",
    "        valid_customers = pd.Series(customers_with_history)\n",
    "    \n",
    "    print(f\"Computing features for {len(valid_customers):,} customers with purchase history before {cutoff_date}\")\n",
    "    if customer_ids is not None:\n",
    "        dropped = len(customer_ids) - len(valid_customers)\n",
    "        if dropped > 0:\n",
    "            print(f\"  (Dropped {dropped} customers without history)\")\n",
    "    \n",
    "    # Create feature matrix\n",
    "    feature_rows = []\n",
    "    for customer_id in valid_customers:\n",
    "        features = create_feature_vector(df, customer_id, cutoff_date)\n",
    "        feature_rows.append(features)\n",
    "    \n",
    "    feature_df = pd.DataFrame(feature_rows)\n",
    "    feature_df.insert(0, 'customer_id', valid_customers.values)\n",
    "    feature_df.insert(1, 'cutoff_date', cutoff_date)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "# Test feature engineering on a single customer\n",
    "test_customer = df['customer_id'].iloc[0]\n",
    "test_cutoff = pd.Timestamp('2019-01-31')\n",
    "\n",
    "print(f\"Testing feature engineering for customer {test_customer} at {test_cutoff}\")\n",
    "features = create_feature_vector(df, test_customer, test_cutoff)\n",
    "print(\"\\nFeature vector:\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88451113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features at cutoff 2019-01-31 00:00:00\n",
      "This may take a moment...\n",
      "(Customers without purchase history before cutoff will be automatically dropped)\n",
      "\n",
      "Computing features for 1,817 customers with purchase history before 2019-01-31 00:00:00\n",
      "\n",
      "Feature matrix shape: (1817, 9)\n",
      "\n",
      "Feature summary statistics:\n",
      "        customer_id          cutoff_date  n_transactions_1m  \\\n",
      "count  1.817000e+03                 1817        1817.000000   \n",
      "mean   5.451729e+06  2019-01-31 00:00:00           4.751789   \n",
      "min    1.001614e+06  2019-01-31 00:00:00           0.000000   \n",
      "25%    3.188310e+06  2019-01-31 00:00:00           0.000000   \n",
      "50%    5.375641e+06  2019-01-31 00:00:00           0.000000   \n",
      "75%    7.756617e+06  2019-01-31 00:00:00           3.000000   \n",
      "max    9.996357e+06  2019-01-31 00:00:00         208.000000   \n",
      "std    2.623948e+06                  NaN          13.280212   \n",
      "\n",
      "       n_transactions_3m  n_transactions_6m  change_rate_3m  \\\n",
      "count        1817.000000        1817.000000     1817.000000   \n",
      "mean           14.635663          28.433682        0.837644   \n",
      "min             0.000000           0.000000     -236.000000   \n",
      "25%             0.000000           0.000000       -1.000000   \n",
      "50%             1.000000           4.000000        0.000000   \n",
      "75%            12.000000          24.000000        2.000000   \n",
      "max           566.000000        1315.000000      196.000000   \n",
      "std            37.224279          73.809159       18.853614   \n",
      "\n",
      "       days_since_last_tx  active_months  month_of_year  \n",
      "count         1817.000000    1817.000000         1817.0  \n",
      "mean           183.668685      20.798569            1.0  \n",
      "min              1.000000       1.000000            1.0  \n",
      "25%              8.000000      20.000000            1.0  \n",
      "50%             64.000000      24.000000            1.0  \n",
      "75%            325.000000      25.000000            1.0  \n",
      "max            759.000000      25.000000            1.0  \n",
      "std            227.560931       6.162282            0.0  \n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cutoff_date</th>\n",
       "      <th>n_transactions_1m</th>\n",
       "      <th>n_transactions_3m</th>\n",
       "      <th>n_transactions_6m</th>\n",
       "      <th>change_rate_3m</th>\n",
       "      <th>days_since_last_tx</th>\n",
       "      <th>active_months</th>\n",
       "      <th>month_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9447359</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435072</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5391951</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3944257</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6223347</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3926262</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>39.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9467115</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4104271</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4121261</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4275069</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id cutoff_date  n_transactions_1m  n_transactions_3m  \\\n",
       "0      9447359  2019-01-31               11.0               46.0   \n",
       "1      1435072  2019-01-31                0.0                0.0   \n",
       "2      5391951  2019-01-31               16.0               44.0   \n",
       "3      3944257  2019-01-31                6.0               12.0   \n",
       "4      6223347  2019-01-31               21.0               36.0   \n",
       "5      3926262  2019-01-31               39.0              140.0   \n",
       "6      9467115  2019-01-31                0.0              136.0   \n",
       "7      4104271  2019-01-31                4.0                8.0   \n",
       "8      4121261  2019-01-31                1.0                1.0   \n",
       "9      4275069  2019-01-31               13.0               79.0   \n",
       "\n",
       "   n_transactions_6m  change_rate_3m  days_since_last_tx  active_months  \\\n",
       "0               74.0            18.0                 6.0           25.0   \n",
       "1                4.0            -4.0               183.0           25.0   \n",
       "2               74.0            14.0                 9.0           25.0   \n",
       "3               28.0            -4.0                 3.0           25.0   \n",
       "4               63.0             9.0                 7.0           25.0   \n",
       "5              184.0            96.0                 1.0           25.0   \n",
       "6              508.0          -236.0                62.0           25.0   \n",
       "7               31.0           -15.0                10.0           25.0   \n",
       "8                1.0             1.0                22.0           25.0   \n",
       "9              219.0           -61.0                 7.0           25.0   \n",
       "\n",
       "   month_of_year  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            1.0  \n",
       "3            1.0  \n",
       "4            1.0  \n",
       "5            1.0  \n",
       "6            1.0  \n",
       "7            1.0  \n",
       "8            1.0  \n",
       "9            1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix for all customers at a specific cutoff date\n",
    "# Example: features as of end of January 2019 (for predicting Feb-Apr 2019)\n",
    "cutoff_date = pd.Timestamp('2019-01-31')\n",
    "\n",
    "print(f\"Creating features at cutoff {cutoff_date}\")\n",
    "print(\"This may take a moment...\")\n",
    "print(\"(Customers without purchase history before cutoff will be automatically dropped)\\n\")\n",
    "\n",
    "# Create feature matrix - single cutoff date for all customers\n",
    "# Only customers with at least one transaction before cutoff_date will be included\n",
    "feature_matrix = create_feature_matrix(df, cutoff_date)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {feature_matrix.shape}\")\n",
    "print(\"\\nFeature summary statistics:\")\n",
    "print(feature_matrix.describe())\n",
    "print(\"\\nFirst few rows:\")\n",
    "feature_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae1e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cutoff: 2019-01-31 | Horizon months: 3\n",
      "Last train cutoff (cutoff + horizon <= test_cutoff): 2018-10-31\n",
      "# train cutoffs: 16 (2017-07-31 .. 2018-10-31)\n",
      "Computing features for 1,412 customers with purchase history before 2017-07-31 00:00:00\n",
      "Computing features for 1,438 customers with purchase history before 2017-08-31 00:00:00\n",
      "Computing features for 1,468 customers with purchase history before 2017-09-30 00:00:00\n",
      "Computing features for 1,514 customers with purchase history before 2017-10-31 00:00:00\n",
      "Computing features for 1,545 customers with purchase history before 2017-11-30 00:00:00\n",
      "Computing features for 1,553 customers with purchase history before 2017-12-31 00:00:00\n",
      "Computing features for 1,573 customers with purchase history before 2018-01-31 00:00:00\n",
      "Computing features for 1,596 customers with purchase history before 2018-02-28 00:00:00\n",
      "Computing features for 1,616 customers with purchase history before 2018-03-31 00:00:00\n",
      "Computing features for 1,639 customers with purchase history before 2018-04-30 00:00:00\n",
      "Computing features for 1,668 customers with purchase history before 2018-05-31 00:00:00\n",
      "Computing features for 1,700 customers with purchase history before 2018-06-30 00:00:00\n",
      "Computing features for 1,727 customers with purchase history before 2018-07-31 00:00:00\n",
      "Computing features for 1,735 customers with purchase history before 2018-08-31 00:00:00\n",
      "Computing features for 1,743 customers with purchase history before 2018-09-30 00:00:00\n",
      "Computing features for 1,773 customers with purchase history before 2018-10-31 00:00:00\n",
      "Computing features for 1,817 customers with purchase history before 2019-01-31 00:00:00\n",
      "\n",
      "Train panel: X=(25700, 7), y_mean=14.980\n",
      "Test  panel: X=(1817, 7), y_mean=9.583\n"
     ]
    }
   ],
   "source": [
    "# Panel dataset training (multiple monthly cutoffs) + held-out test cutoff\n",
    "#\n",
    "# Cutoff rule:\n",
    "# - Features X_{i,t} use ONLY transactions strictly before the cutoff: date < t\n",
    "# - Labels   y_{i,t} count transactions in the future horizon:            [t, t + horizon)\n",
    "#\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.metrics import mean_tweedie_deviance, mean_absolute_error, mean_squared_error\n",
    "\n",
    "POWER = 1.5\n",
    "HORIZON_MONTHS = 3\n",
    "TEST_CUTOFF = pd.Timestamp('2019-01-31')\n",
    "\n",
    "\n",
    "def _norm_ts(x) -> pd.Timestamp:\n",
    "    x = pd.Timestamp(x)\n",
    "    if x.tz is not None:\n",
    "        x = x.tz_localize(None)\n",
    "    return x.normalize()\n",
    "\n",
    "\n",
    "def make_future_tx_count(df: pd.DataFrame, cutoff_date: pd.Timestamp, horizon_months: int) -> pd.Series:\n",
    "    \"\"\"y_i(t) = #tx for customer i in [t, t+horizon).\"\"\"\n",
    "    cutoff_date = _norm_ts(cutoff_date)\n",
    "    horizon_end = _norm_ts(cutoff_date + pd.DateOffset(months=horizon_months))\n",
    "    mask = (df['date'] >= cutoff_date) & (df['date'] < horizon_end)\n",
    "    y = df.loc[mask].groupby('customer_id').size()\n",
    "    y.name = 'y_future_tx_count'\n",
    "    return y\n",
    "\n",
    "\n",
    "def build_panel_dataset(df: pd.DataFrame, cutoffs, horizon_months: int):\n",
    "    \"\"\"Return X, y, keys for a stacked (customer_id, cutoff_date) panel.\n",
    "\n",
    "    - keys: customer_id, cutoff_date (join-back only)\n",
    "    - X: numeric features only\n",
    "    - y: aligned to keys, defaults to 0 if customer has no tx in horizon\n",
    "\n",
    "    Uniqueness assertion:\n",
    "    - exactly one row per (customer_id, cutoff_date)\n",
    "    \"\"\"\n",
    "    cutoffs = [_norm_ts(c) for c in cutoffs]\n",
    "\n",
    "    keys_parts = []\n",
    "    X_parts = []\n",
    "    y_parts = []\n",
    "\n",
    "    for cutoff in cutoffs:\n",
    "        fm = create_feature_matrix(df, cutoff)\n",
    "\n",
    "        # exactly one row per (customer_id, cutoff_date)\n",
    "        assert not fm[['customer_id', 'cutoff_date']].duplicated().any()\n",
    "\n",
    "        keys = fm[['customer_id', 'cutoff_date']].copy()\n",
    "        X = fm.drop(columns=['customer_id', 'cutoff_date'])\n",
    "\n",
    "        # X must be numeric only\n",
    "        non_numeric = X.select_dtypes(exclude='number').columns.tolist()\n",
    "        assert non_numeric == [], f\"Non-numeric feature columns found: {non_numeric}\"\n",
    "\n",
    "        y_s = make_future_tx_count(df, cutoff, horizon_months)\n",
    "        y = y_s.reindex(keys['customer_id']).fillna(0).to_numpy(dtype=float)\n",
    "\n",
    "        keys_parts.append(keys)\n",
    "        X_parts.append(X)\n",
    "        y_parts.append(y)\n",
    "\n",
    "    keys_all = pd.concat(keys_parts, ignore_index=True)\n",
    "    X_all = pd.concat(X_parts, ignore_index=True)\n",
    "    y_all = np.concatenate(y_parts, axis=0)\n",
    "\n",
    "    # Uniqueness + alignment assertions\n",
    "    assert not keys_all[['customer_id', 'cutoff_date']].duplicated().any(), \"Duplicate (customer_id, cutoff_date) rows\"\n",
    "    assert len(X_all) == len(keys_all) == len(y_all)\n",
    "\n",
    "    return X_all, y_all, keys_all\n",
    "\n",
    "\n",
    "# --- Time split ---\n",
    "test_cutoff = _norm_ts(TEST_CUTOFF)\n",
    "last_train_cutoff = _norm_ts(test_cutoff - pd.DateOffset(months=HORIZON_MONTHS))\n",
    "\n",
    "# Train cutoffs are all month-ends where cutoff + horizon <= test_cutoff\n",
    "# We require at least 6 months of history for the 6m features, so we start training\n",
    "# at the first month-end cutoff >= (min_date + 6 months).\n",
    "# Pandas >= 3 uses 'ME' for month-end (old alias 'M' was removed)\n",
    "start_train_cutoff = (df['date'].min() + pd.DateOffset(months=6)).normalize() + pd.offsets.MonthEnd(0)\n",
    "train_cutoffs = list(pd.date_range(start=start_train_cutoff, end=last_train_cutoff, freq='ME'))\n",
    "train_cutoffs = [_norm_ts(c) for c in train_cutoffs]\n",
    "\n",
    "print(f\"Test cutoff: {test_cutoff.date()} | Horizon months: {HORIZON_MONTHS}\")\n",
    "print(f\"Last train cutoff (cutoff + horizon <= test_cutoff): {last_train_cutoff.date()}\")\n",
    "print(f\"# train cutoffs: {len(train_cutoffs)} ({train_cutoffs[0].date()} .. {train_cutoffs[-1].date()})\")\n",
    "\n",
    "X_train, y_train, keys_train = build_panel_dataset(df, train_cutoffs, HORIZON_MONTHS)\n",
    "X_test, y_test, keys_test = build_panel_dataset(df, [test_cutoff], HORIZON_MONTHS)\n",
    "\n",
    "print(f\"\\nTrain panel: X={X_train.shape}, y_mean={y_train.mean():.3f}\")\n",
    "print(f\"Test  panel: X={X_test.shape}, y_mean={y_test.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e4775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cutoff: 2019-01-31 | Horizon months: 3\n",
      "Last train cutoff (cutoff + horizon <= test_cutoff): 2018-10-31\n",
      "# train cutoffs: 16 (2017-07-31 .. 2018-10-31)\n",
      "Computing features for 1,412 customers with purchase history before 2017-07-31 00:00:00\n",
      "Computing features for 1,438 customers with purchase history before 2017-08-31 00:00:00\n",
      "Computing features for 1,468 customers with purchase history before 2017-09-30 00:00:00\n",
      "Computing features for 1,514 customers with purchase history before 2017-10-31 00:00:00\n",
      "Computing features for 1,545 customers with purchase history before 2017-11-30 00:00:00\n",
      "Computing features for 1,553 customers with purchase history before 2017-12-31 00:00:00\n",
      "Computing features for 1,573 customers with purchase history before 2018-01-31 00:00:00\n",
      "Computing features for 1,596 customers with purchase history before 2018-02-28 00:00:00\n",
      "Computing features for 1,616 customers with purchase history before 2018-03-31 00:00:00\n",
      "Computing features for 1,639 customers with purchase history before 2018-04-30 00:00:00\n",
      "Computing features for 1,668 customers with purchase history before 2018-05-31 00:00:00\n",
      "Computing features for 1,700 customers with purchase history before 2018-06-30 00:00:00\n",
      "Computing features for 1,727 customers with purchase history before 2018-07-31 00:00:00\n",
      "Computing features for 1,735 customers with purchase history before 2018-08-31 00:00:00\n",
      "Computing features for 1,743 customers with purchase history before 2018-09-30 00:00:00\n",
      "Computing features for 1,773 customers with purchase history before 2018-10-31 00:00:00\n",
      "Computing features for 1,817 customers with purchase history before 2019-01-31 00:00:00\n",
      "\n",
      "Train panel: X=(25700, 7), y_mean=14.980\n",
      "Test  panel: X=(1817, 7), y_mean=9.583\n",
      "Test target: zero_rate=0.461 | p50=1.000 | p95=45.000\n",
      "\n",
      "=== TweedieRegressor (held-out test cutoff only) ===\n",
      "Mean Tweedie deviance: 10.8096\n",
      "MAE:  15.7937\n",
      "RMSE: 28.2593\n",
      "NMSE:  8.6963\n",
      "NRMSE: 2.9489\n",
      "\n",
      "=== Baseline A (held-out test cutoff only) ===\n",
      "Mean Tweedie deviance: 40656.6652\n",
      "MAE:  8.4606\n",
      "RMSE: 22.4675\n",
      "NMSE:  5.4970\n",
      "NRMSE: 2.3446\n",
      "MAE improvement vs baseline: -86.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zelmokri/.cache/pypoetry/virtualenvs/quod-tha-fVa_CEgS-py3.11/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Tweedie GLM ---\n",
    "model = TweedieRegressor(power=POWER, link='log', alpha=0.0, max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = np.clip(model.predict(X_test), 0.0, None)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# NOTE: For Tweedie deviance with 1 < power < 2, y_pred must be strictly positive.\n",
    "# We keep MAE/RMSE on the original predictions, and only floor preds for deviance.\n",
    "EPS_DEV = 1e-9\n",
    "y_pred_dev = np.maximum(y_pred, EPS_DEV)\n",
    "dev = mean_tweedie_deviance(y_test, y_pred_dev, power=POWER)\n",
    "\n",
    "# Normalized MSE/RMSE (by mean target)\n",
    "mu = float(np.mean(y_test))\n",
    "eps = 1e-12\n",
    "nmse = mse / ((mu ** 2) + eps)\n",
    "nrmse = rmse / (mu + eps)\n",
    "\n",
    "# Test target diagnostics\n",
    "zero_rate = float(np.mean(y_test == 0))\n",
    "p50 = float(np.quantile(y_test, 0.50))\n",
    "p95 = float(np.quantile(y_test, 0.95))\n",
    "print(f\"Test target: zero_rate={zero_rate:.3f} | p50={p50:.3f} | p95={p95:.3f}\")\n",
    "\n",
    "print(\"\\n=== TweedieRegressor (held-out test cutoff only) ===\")\n",
    "print(f\"Mean Tweedie deviance: {dev:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"NMSE:  {nmse:.4f}\")\n",
    "print(f\"NRMSE: {nrmse:.4f}\")\n",
    "\n",
    "# --- Baseline A: y_hat = tx_last_3m = N_i(t-3, t) ---\n",
    "y_pred_base = X_test['n_transactions_3m'].to_numpy(dtype=float)\n",
    "\n",
    "mse_b = mean_squared_error(y_test, y_pred_base)\n",
    "rmse_b = mse_b ** 0.5\n",
    "mae_b = mean_absolute_error(y_test, y_pred_base)\n",
    "\n",
    "# Tweedie deviance with 1 < power < 2 requires strictly positive predictions\n",
    "y_pred_base_dev = np.maximum(y_pred_base, EPS_DEV)\n",
    "dev_b = mean_tweedie_deviance(y_test, y_pred_base_dev, power=POWER)\n",
    "\n",
    "nmse_b = mse_b / ((mu ** 2) + eps)\n",
    "nrmse_b = rmse_b / (mu + eps)\n",
    "\n",
    "print(\"\\n=== Baseline A (held-out test cutoff only) ===\")\n",
    "print(f\"Mean Tweedie deviance: {dev_b:.4f}\")\n",
    "print(f\"MAE:  {mae_b:.4f}\")\n",
    "print(f\"RMSE: {rmse_b:.4f}\")\n",
    "print(f\"NMSE:  {nmse_b:.4f}\")\n",
    "print(f\"NRMSE: {nrmse_b:.4f}\")\n",
    "print(f\"MAE improvement vs baseline: {(mae_b - mae) / mae_b:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoostRegressor (held-out test cutoff only) ===\n",
      "RMSE (eval metric): 18.3196\n",
      "MAE: 7.2372\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost (non-linear) with time-based validation + early stopping ---\n",
    "# We use a single validation cutoff strictly before the test cutoff to tune model capacity\n",
    "# without ever touching the held-out test cutoff.\n",
    "# Early stopping controls capacity by selecting the best number of trees.\n",
    "# Then we retrain on all available pre-test cutoffs using that best number of trees.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "VAL_CUTOFF = pd.Timestamp(\"2018-12-31\")\n",
    "\n",
    "val_cutoff = _norm_ts(VAL_CUTOFF)\n",
    "test_cutoff = _norm_ts(TEST_CUTOFF)\n",
    "assert val_cutoff < test_cutoff, \"VAL_CUTOFF must be strictly before TEST_CUTOFF\"\n",
    "\n",
    "# Require at least 6 months of history for 6m features\n",
    "start_train_cutoff = (df[\"date\"].min() + pd.DateOffset(months=6)).normalize() + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# --- Early-stopping split (train cutoffs must satisfy train_cutoff + horizon <= VAL_CUTOFF) ---\n",
    "last_es_train_cutoff = _norm_ts(val_cutoff - pd.DateOffset(months=HORIZON_MONTHS))\n",
    "es_train_cutoffs = list(pd.date_range(start=start_train_cutoff, end=last_es_train_cutoff, freq=\"ME\"))\n",
    "\n",
    "X_train_es, y_train_es, _ = build_panel_dataset(df, es_train_cutoffs, HORIZON_MONTHS)\n",
    "X_val, y_val, _ = build_panel_dataset(df, [val_cutoff], HORIZON_MONTHS)\n",
    "\n",
    "xgb_es = XGBRegressor(\n",
    "    objective=\"count:poisson\",\n",
    "    eval_metric=\"rmse\",\n",
    "    n_estimators=4000,\n",
    "    max_depth=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xgb_es.fit(\n",
    "    X_train_es,\n",
    "    y_train_es,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "best_iteration = int(xgb_es.best_iteration)\n",
    "best_n_estimators = best_iteration + 1  # best_iteration is 0-based\n",
    "\n",
    "# --- Final training split (all cutoffs where cutoff + horizon <= TEST_CUTOFF) ---\n",
    "last_full_train_cutoff = _norm_ts(test_cutoff - pd.DateOffset(months=HORIZON_MONTHS))\n",
    "full_train_cutoffs = list(pd.date_range(start=start_train_cutoff, end=last_full_train_cutoff, freq=\"ME\"))\n",
    "\n",
    "X_train_full, y_train_full, _ = build_panel_dataset(df, full_train_cutoffs, HORIZON_MONTHS)\n",
    "X_test, y_test, _ = build_panel_dataset(df, [test_cutoff], HORIZON_MONTHS)\n",
    "\n",
    "xgb_final = XGBRegressor(\n",
    "    objective=\"count:poisson\",\n",
    "    eval_metric=\"rmse\",\n",
    "    n_estimators=best_n_estimators,\n",
    "    max_depth=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_pred_xgb = np.clip(xgb_final.predict(X_test), 0.0, None)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb) ** 0.5\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"\\n=== XGBoost (time validation + early stopping; evaluated on held-out test cutoff only) ===\")\n",
    "print(f\"VAL_CUTOFF: {val_cutoff.date()} | best_iteration={best_iteration} | n_estimators(final)={best_n_estimators}\")\n",
    "print(f\"RMSE (test): {rmse_xgb:.4f}\")\n",
    "print(f\"MAE  (test): {mae_xgb:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales-forecast (poetry)",
   "language": "python",
   "name": "sales-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
