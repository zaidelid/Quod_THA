{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7064e66e",
   "metadata": {},
   "source": [
    "# Transaction Prediction Model\n",
    "\n",
    "This notebook focuses on building a predictive model for transaction counts per customer.\n",
    "\n",
    "## Approach\n",
    "- **Problem formulation**: Conditional count modeling (predicting number of transactions)\n",
    "- **Model**: GLM with Tweedie loss (1 < p < 2) as approximation to Negative Binomial\n",
    "- **Features**: Time-aware features (recency, frequency, rolling windows)\n",
    "- **Temporal splitting**: Strict time-based train/test splits to avoid leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42849b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Bootstrap import path for notebooks: add repo root so we can import `src.*`.\n",
    "# IMPORTANT: we intentionally do NOT use this variable for paths; paths come from src.config.\n",
    "_BOOTSTRAP_ROOT = Path().resolve().parent\n",
    "if str(_BOOTSTRAP_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(_BOOTSTRAP_ROOT))\n",
    "\n",
    "# Import project configuration (single source of truth for paths)\n",
    "from src.config import PROJECT_ROOT, FIGURES_DIR, OUTPUTS_DIR, MODELS_DIR, DATA_PROCESSED, ensure_directories\n",
    "\n",
    "# Ensure directories exist\n",
    "ensure_directories()\n",
    "\n",
    "# Use config paths\n",
    "OUTPUTS = OUTPUTS_DIR\n",
    "FIGURES = FIGURES_DIR\n",
    "\n",
    "print(\"✓ Imports loaded\")\n",
    "print(f\"✓ Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d383102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "from src.data import load_and_process_transactions\n",
    "import importlib, src.data as data\n",
    "importlib.reload(data)\n",
    "\n",
    "df = load_and_process_transactions(force_reprocess=False)\n",
    "\n",
    "print(f\"Loaded {len(df):,} transactions\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Unique customers: {df['customer_id'].nunique():,}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d383102",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Build time-aware features for customer $i$ at cutoff time $t$:\n",
    "\n",
    "- $N_i(t-1, t)$: Transactions in last 1 month\n",
    "- $N_i(t-3, t)$: Transactions in last 3 months\n",
    "- $N_i(t-6, t)$: Transactions in last 6 months\n",
    "- $N_i(t-3, t) - N_i(t-6, t-3)$: Change in transaction rate\n",
    "- `days_since_last_tx(i, t)`: Recency feature\n",
    "- `active_months(i, t)`: Number of active months\n",
    "- `month_of_year(t)`: Seasonal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1aa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (imported from src)\n",
    "from src.features import create_feature_vector, create_feature_matrix\n",
    "\n",
    "# Quick smoke-check: one customer at one cutoff\n",
    "test_customer = df[\"customer_id\"].iloc[0]\n",
    "test_cutoff = pd.Timestamp(\"2019-01-31\")\n",
    "\n",
    "print(f\"Testing feature engineering for customer {test_customer} at {test_cutoff}\")\n",
    "features = create_feature_vector(df, test_customer, test_cutoff)\n",
    "print(\"\\nFeature vector:\")\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88451113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create feature matrix for all customers at a specific cutoff date\n",
    "# # Example: features as of end of January 2019 (for predicting Feb-Apr 2019)\n",
    "# cutoff_date = pd.Timestamp('2019-01-31')\n",
    "\n",
    "# print(f\"Creating features at cutoff {cutoff_date}\")\n",
    "# print(\"This may take a moment...\")\n",
    "# print(\"(Customers without purchase history before cutoff will be automatically dropped)\\n\")\n",
    "\n",
    "# # Create feature matrix - single cutoff date for all customers\n",
    "# # Only customers with at least one transaction before cutoff_date will be included\n",
    "# feature_matrix = create_feature_matrix(df, cutoff_date)\n",
    "\n",
    "# print(f\"\\nFeature matrix shape: {feature_matrix.shape}\")\n",
    "# print(\"\\nFeature summary statistics:\")\n",
    "# print(feature_matrix.describe())\n",
    "# print(\"\\nFirst few rows:\")\n",
    "# feature_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae1e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive no-leakage panel dataset (precompute ONCE for all possible cutoffs)\n",
    "#\n",
    "# Cutoff rule (no leakage):\n",
    "# - Features X_{i,t} use ONLY transactions strictly before the cutoff: date < t\n",
    "# - Labels   y_{i,t} count transactions in the future horizon:        [t, t + horizon)\n",
    "#\n",
    "# We build a comprehensive panel for every valid month-end cutoff from the earliest\n",
    "# possible prediction month (requires 6m history) up to (last_date - horizon).\n",
    "# Then for any cutoff, we slice the already-built panel instead of recomputing features.\n",
    "\n",
    "from src.panel import build_or_load_full_panel_dataset\n",
    "from src.builder import (\n",
    "    baseline_a_predict,\n",
    "    train_tweedie_model,\n",
    "    tweedie_predict,\n",
    "    train_or_load_xgb_poisson_for_cutoff,\n",
    "    evaluate_xgb_poisson_on_cutoff,\n",
    ")\n",
    "\n",
    "HORIZON_MONTHS = 3\n",
    "\n",
    "panel = build_or_load_full_panel_dataset(\n",
    "    df,\n",
    "    horizon_months=HORIZON_MONTHS,\n",
    "    min_history_months=6,\n",
    "    cache_path=PROJECT_ROOT / f\"data/processed/panel_h{HORIZON_MONTHS}_mh6.joblib\",\n",
    "    force_rebuild=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Full panel built/loaded: X={panel.X.shape}, #cutoffs={len(panel.cutoffs)} \"\n",
    "    f\"({panel.cutoffs[0].date()} .. {panel.cutoffs[-1].date()})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few time-based \"tests\" in 2019 using the prebuilt full panel.\n",
    "# For each cutoff T:\n",
    "# - train uses only cutoffs <= (T - horizon)\n",
    "# - XGBoost early stopping uses validation cutoff V = (T - 2 months), never touching T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_tweedie_deviance\n",
    "\n",
    "POWER = 1.5\n",
    "EPS_DEV = 1e-9\n",
    "\n",
    "cutoffs_2019 = [\n",
    "    pd.Timestamp(\"2019-01-31\"),\n",
    "    pd.Timestamp(\"2019-03-31\"),\n",
    "    pd.Timestamp(\"2019-07-31\"),\n",
    "]\n",
    "\n",
    "# XGB configuration (passed into the training function)\n",
    "XGB_VAL_OFFSET_MONTHS = 2\n",
    "XGB_MAX_DEPTH = 5\n",
    "XGB_N_ESTIMATORS_MAX = 5000\n",
    "XGB_EARLY_STOPPING_ROUNDS = 50\n",
    "\n",
    "for cutoff in cutoffs_2019:\n",
    "    cutoff = cutoff.normalize() + pd.offsets.MonthEnd(0)\n",
    "    last_train_cutoff = (cutoff - pd.DateOffset(months=HORIZON_MONTHS)).normalize() + pd.offsets.MonthEnd(0)\n",
    "    train_cutoffs = [c for c in panel.cutoffs if c <= last_train_cutoff]\n",
    "\n",
    "    X_train, y_train, _ = panel.for_cutoffs(train_cutoffs)\n",
    "    X_test, y_test, _ = panel.for_cutoff(cutoff)\n",
    "\n",
    "    # --- Baseline A ---\n",
    "    yb = baseline_a_predict(X_test)\n",
    "    rmse_b = mean_squared_error(y_test, yb) ** 0.5\n",
    "    mae_b = mean_absolute_error(y_test, yb)\n",
    "\n",
    "    # --- Tweedie (optional reference) ---\n",
    "    tw_model = train_tweedie_model(X_train, y_train, power=POWER)\n",
    "    y_tw = tweedie_predict(tw_model, X_test)\n",
    "    rmse_tw = mean_squared_error(y_test, y_tw) ** 0.5\n",
    "    mae_tw = mean_absolute_error(y_test, y_tw)\n",
    "    dev_tw = mean_tweedie_deviance(y_test, np.maximum(y_tw, EPS_DEV), power=POWER)\n",
    "\n",
    "    # --- XGBoost Poisson with early stopping on val=T-2mo and caching ---\n",
    "    xgb_model, meta = train_or_load_xgb_poisson_for_cutoff(\n",
    "        panel,\n",
    "        cutoff,\n",
    "        horizon_months=HORIZON_MONTHS,\n",
    "        val_offset_months=XGB_VAL_OFFSET_MONTHS,\n",
    "        max_depth=XGB_MAX_DEPTH,\n",
    "        n_estimators_max=XGB_N_ESTIMATORS_MAX,\n",
    "        early_stopping_rounds=XGB_EARLY_STOPPING_ROUNDS,\n",
    "        model_dir=MODELS_DIR,\n",
    "    )\n",
    "    m = evaluate_xgb_poisson_on_cutoff(xgb_model, panel, cutoff)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(f\"CUTOFF={cutoff.date()} | horizon={HORIZON_MONTHS} | train_cutoffs={len(train_cutoffs)}\")\n",
    "    print(f\"BaselineA      RMSE={rmse_b:.4f} | MAE={mae_b:.4f}\")\n",
    "    print(f\"Tweedie(power={POWER}) RMSE={rmse_tw:.4f} | MAE={mae_tw:.4f} | dev={dev_tw:.4f}\")\n",
    "    print(\n",
    "        f\"XGBPoisson     RMSE={m['rmse']:.4f} | MAE={m['mae']:.4f} | \"\n",
    "        f\"val={pd.Timestamp(meta['val_cutoff']).date()} | n_estimators={meta['n_estimators']}\"\n",
    "    )\n",
    "    print(f\"Saved model: {meta['saved_to']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (moved) XGBoost training is now implemented in `src/builder/xgb_poisson.py` and exercised in the cell above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bfdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (moved) See the 2019 cutoff loop cell above; models are cached under `models/` per cutoff.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales-forecast (poetry)",
   "language": "python",
   "name": "sales-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
