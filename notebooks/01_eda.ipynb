{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1c3b40",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This notebook focuses on understanding the transaction dataset before modeling. We'll:\n",
    "- Load and inspect the raw data\n",
    "- Validate data quality (timestamps, missing values, duplicates)\n",
    "- Analyze basic distributions\n",
    "- Generate required descriptive plots\n",
    "- Document key observations for modeling decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ce6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports (import these first for faster startup)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Bootstrap import path for notebooks: add repo root so we can import `src.*`.\n",
    "# IMPORTANT: we intentionally do NOT use this variable for paths; paths come from src.config.\n",
    "_BOOTSTRAP_ROOT = Path().resolve().parent\n",
    "if str(_BOOTSTRAP_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(_BOOTSTRAP_ROOT))\n",
    "\n",
    "# Import project configuration (single source of truth for paths)\n",
    "from src.config import PROJECT_ROOT, DATA_RAW, DATA_PROCESSED, FIGURES_DIR, OUTPUTS_DIR, MODELS_DIR, ensure_directories\n",
    "\n",
    "# Ensure all directories exist\n",
    "ensure_directories()\n",
    "\n",
    "# Use config paths (aliased for backward compatibility in notebook)\n",
    "OUTPUTS = OUTPUTS_DIR\n",
    "FIGURES = FIGURES_DIR\n",
    "\n",
    "print(\"✓ Core imports loaded\")\n",
    "print(f\"✓ Project root: {PROJECT_ROOT}\")\n",
    "print(f\"✓ Data raw directory: {DATA_RAW}\")\n",
    "print(f\"✓ Data processed directory: {DATA_PROCESSED}\")\n",
    "print(f\"✓ Outputs directory: {OUTPUTS_DIR}\")\n",
    "print(f\"✓ Figures directory: {FIGURES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b569b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib setup (load separately to avoid slowing down initial imports)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plotting style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except OSError:\n",
    "    # Fallback for older matplotlib versions\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "print(\"✓ Matplotlib configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75204ed9",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load and combine the raw transaction files. Data cleaning (duplicate removal, product name consolidation, date conversion) is handled by `src.data.load_and_process_transactions()`, which saves cleaned data to `data/processed/` for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data loading function from src\n",
    "from src.data import load_and_process_transactions\n",
    "\n",
    "# Load and process transactions (will save to data/processed if not already processed)\n",
    "# Uses paths from config.py by default\n",
    "df = load_and_process_transactions(\n",
    "    force_reprocess=False  # Set to True to force reprocessing\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded cleaned data:\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02629a5",
   "metadata": {},
   "source": [
    "## 2. Schema and Data Type Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect schema\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nDataFrame info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Dates are already converted to datetime by load_and_process_transactions()\n",
    "# This cell is for validation/verification\n",
    "\n",
    "# Check the date types (should already be datetime)\n",
    "print(\"Date column type:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Date column is datetime: {pd.api.types.is_datetime64_any_dtype(df['date'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e68ec",
   "metadata": {},
   "source": [
    "## 3. Data Validation\n",
    "\n",
    "Check for missing values, duplicates, and validate timestamp consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing: {df.isnull().sum().sum()}\")\n",
    "\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Duplicate (customer_id, product_id, date) combinations: {df.duplicated(subset=['customer_id', 'product_id', 'date']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics on key columns\n",
    "print(\"Customer ID statistics:\")\n",
    "print(f\"Unique customers: {df['customer_id'].nunique():,}\")\n",
    "print(f\"Customer ID range: {df['customer_id'].min()} to {df['customer_id'].max()}\")\n",
    "\n",
    "print(\"\\nProduct ID statistics:\")\n",
    "print(f\"Unique products: {df['product_id'].nunique()}\")\n",
    "print(f\"Products: {sorted(df['product_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9876e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect odd / potentially invalid product values\n",
    "# suspicious_products = [\"Not a make\", \"Undefined\", \"├ÅTS\"]\n",
    "\n",
    "# print(\"Suspicious product values and their counts:\\n\")\n",
    "# for p in suspicious_products:\n",
    "#     count = (df[\"product_id\"] == p).sum()\n",
    "#     print(f\"- {p!r}: {count} rows\")\n",
    "\n",
    "# print(\"\\nExamples of rows with suspicious products:\\n\")\n",
    "# for p in suspicious_products:\n",
    "#     subset = df[df[\"product_id\"] == p].head(5)\n",
    "#     print(f\"=== {p!r} (showing up to 5 rows) ===\")\n",
    "#     if subset.empty:\n",
    "#         print(\"No rows found.\\n\")\n",
    "#     else:\n",
    "#         print(subset)\n",
    "#         print()\n",
    "\n",
    "# # Share relative frequencies to understand importance\n",
    "# product_counts = df[\"product_id\"].value_counts()\n",
    "# total_rows = len(df)\n",
    "\n",
    "# print(\"Relative frequency of suspicious products:\\n\")\n",
    "# for p in suspicious_products:\n",
    "#     freq = product_counts.get(p, 0)\n",
    "#     pct = 100 * freq / total_rows\n",
    "#     print(f\"- {p!r}: {freq} rows ({pct:.4f}% of all transactions)\")\n",
    "\n",
    "# # Baseline comparison\n",
    "# normal_counts = product_counts.drop(labels=[p for p in suspicious_products if p in product_counts.index])\n",
    "\n",
    "# print(\"\\nBaseline for normal brands (top 2 most frequent):\")\n",
    "# for brand, cnt in normal_counts.head(2).items():\n",
    "#     pct = 100 * cnt / total_rows\n",
    "#     print(f\"- {brand!r}: {cnt} rows ({pct:.4f}% of all transactions)\")\n",
    "\n",
    "# print(\"\\nBaseline for normal brands (bottom 2 least frequent):\")\n",
    "# for brand, cnt in normal_counts.tail(2).items():\n",
    "#     pct = 100 * cnt / total_rows\n",
    "#     print(f\"- {brand!r}: {cnt} rows ({pct:.4f}% of all transactions)\")\n",
    "\n",
    "# # Aggregate baseline: mean/median counts across normal brands\n",
    "# normal_mean = normal_counts.mean()\n",
    "# normal_median = normal_counts.median()\n",
    "# print(\"\\nAggregate baseline for normal brands:\")\n",
    "# print(f\"- Mean transactions per normal brand: {normal_mean:.2f}\")\n",
    "# print(f\"- Median transactions per normal brand: {normal_median:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odd_products = [\"Not a make\", \"Undefined\", \"├ÅTS\"]\n",
    "\n",
    "# print(\"Before recoding (selected labels):\")\n",
    "# print(df[\"product_id\"].value_counts().loc[odd_products])\n",
    "\n",
    "# # Replace these labels by 'Other' in-place\n",
    "# replacement_map = {p: \"Other\" for p in odd_products}\n",
    "# df[\"product_id\"] = df[\"product_id\"].replace(replacement_map)\n",
    "\n",
    "# print(\"\\nAfter recoding:\")\n",
    "# print(df[\"product_id\"].value_counts().loc[[\"Other\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3781a44",
   "metadata": {},
   "source": [
    "## 4. Basic Distributions\n",
    "\n",
    "Analyze transactions per customer, per product, and over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3161338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions per customer\n",
    "transactions_per_customer = df.groupby('customer_id').size()\n",
    "print(\"Transactions per customer - Summary statistics:\")\n",
    "print(transactions_per_customer.describe())\n",
    "print(f\"\\nMedian: {transactions_per_customer.median():.1f}\")\n",
    "print(f\"Total customers: {len(transactions_per_customer):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0feb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions per product\n",
    "transactions_per_product = df.groupby('product_id').size().sort_values(ascending=False)\n",
    "print(\"Transactions per product:\")\n",
    "print(transactions_per_product)\n",
    "print(f\"\\nTotal products: {len(transactions_per_product)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions over time (by month)\n",
    "df['year_month'] = df['date'].dt.to_period('M')\n",
    "transactions_over_time = df.groupby('year_month').size()\n",
    "\n",
    "print(\"Transactions per month:\")\n",
    "print(transactions_over_time)\n",
    "print(f\"\\nDate range: {transactions_over_time.index.min()} to {transactions_over_time.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87f5b8",
   "metadata": {},
   "source": [
    "## 5. Required Plots\n",
    "\n",
    "### 5.1 Customer Activity Ranking\n",
    "\n",
    "Create an ordered (descending) plot showing total number of transactions per customer from most active to least active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1237889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort customers by transaction count (descending)\n",
    "customer_activity = transactions_per_customer.sort_values(ascending=False)\n",
    "\n",
    "# Optionally focus on the top N most active customers to get a tighter view\n",
    "TOP_N = None  # e.g. set to 500 to zoom in; keep as None to use all customers\n",
    "if TOP_N is not None:\n",
    "    customer_activity_plot = customer_activity.iloc[:TOP_N]\n",
    "else:\n",
    "    customer_activity_plot = customer_activity\n",
    "\n",
    "# Create a tight bar plot (histogram-like) of descending transactions per customer\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(range(len(customer_activity_plot)), customer_activity_plot.values, width=1.0)\n",
    "ax.set_xlim(-1, len(customer_activity_plot))\n",
    "ax.set_xlabel('Customer Rank (Most Active to Least Active)', fontsize=12)\n",
    "ax.set_ylabel('Total Number of Transactions', fontsize=12)\n",
    "ax.set_title('Customer Activity Ranking: Total Transactions per Customer', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add some statistics as text\n",
    "ax.text(0.02, 0.98,\n",
    "        f'Total Customers: {len(customer_activity):,}\\nMax Transactions: {customer_activity.max()}\\nMedian: {customer_activity.median():.1f}',\n",
    "        transform=ax.transAxes, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / 'customer_activity_ranking.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960aaa2",
   "metadata": {},
   "source": [
    "### 5.2 Monthly Product Transaction Frequency (2018)\n",
    "\n",
    "For any product ID, create a plot showing its transaction frequency per month for the year 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ed961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for 2018\n",
    "df_2018 = df[df['date'].dt.year == 2018].copy()\n",
    "\n",
    "# Get monthly transaction counts per product for 2018\n",
    "monthly_product_counts = df_2018.groupby(['product_id', 'year_month']).size().reset_index(name='transaction_count')\n",
    "monthly_product_counts['year_month'] = monthly_product_counts['year_month'].astype(str)\n",
    "\n",
    "# Get all products and all months in 2018\n",
    "all_products = sorted(df['product_id'].unique())\n",
    "all_months_2018 = [f'2018-{i:02d}' for i in range(1, 13)]\n",
    "\n",
    "# Create a complete grid (products x months) and fill missing with 0\n",
    "complete_grid = pd.MultiIndex.from_product([all_products, all_months_2018], names=['product_id', 'year_month'])\n",
    "monthly_product_counts_complete = monthly_product_counts.set_index(['product_id', 'year_month']).reindex(complete_grid, fill_value=0).reset_index()\n",
    "\n",
    "print(f\"Products in dataset: {all_products}\")\n",
    "print(f\"\\nSample of monthly counts:\")\n",
    "print(monthly_product_counts_complete.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d60992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for all products\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Use a colormap to generate many distinct colors (more than default 10)\n",
    "# 'tab20' has 20 colors, 'tab20c' has 20 more, we can cycle through them\n",
    "import matplotlib.cm as cm\n",
    "n_products = len(all_products)\n",
    "# Use a colormap that can generate many colors\n",
    "colormap = cm.get_cmap('tab20')  # Has 20 distinct colors\n",
    "if n_products > 20:\n",
    "    # For more than 20 products, use a continuous colormap and sample evenly\n",
    "    colormap = cm.get_cmap('hsv')  # Can generate infinite distinct colors\n",
    "\n",
    "# Plot each product with distinct colors\n",
    "for idx, product in enumerate(all_products):\n",
    "    product_data = monthly_product_counts_complete[monthly_product_counts_complete['product_id'] == product]\n",
    "    # Generate color from colormap, evenly spaced\n",
    "    color = colormap(idx / max(n_products - 1, 1))  # Normalize to [0, 1]\n",
    "    ax.plot(product_data['year_month'], product_data['transaction_count'], \n",
    "            marker='o', label=product, linewidth=2, markersize=6, color=color)\n",
    "\n",
    "ax.set_xlabel('Month (2018)', fontsize=12)\n",
    "ax.set_ylabel('Transaction Frequency', fontsize=12)\n",
    "ax.set_title('Monthly Transaction Frequency per Product (2018)', fontsize=14, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / 'monthly_product_frequency_2018.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a8133",
   "metadata": {},
   "source": [
    "## 6. Additional Exploratory Analysis\n",
    "\n",
    "### 6.1 Overall Transaction Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6721b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overall transaction volume over time\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(transactions_over_time.index.astype(str), transactions_over_time.values, \n",
    "        marker='o', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Month', fontsize=12)\n",
    "ax.set_ylabel('Number of Transactions', fontsize=12)\n",
    "ax.set_title('Total Transactions Over Time', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / 'transactions_over_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactional trends by year (side by side comparison)\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Get unique years and sort them\n",
    "years = sorted(df['year'].unique())\n",
    "n_years = len(years)\n",
    "\n",
    "# Create subplots: one per year, arranged horizontally\n",
    "fig, axes = plt.subplots(1, n_years, figsize=(6*n_years, 5), sharey=True)\n",
    "\n",
    "for idx, year in enumerate(years):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Filter data for this year\n",
    "    year_data = df[df['year'] == year]\n",
    "    \n",
    "    # Group by month and count transactions\n",
    "    monthly_counts = year_data.groupby('month').size().sort_index()\n",
    "    \n",
    "    # Plot monthly trends\n",
    "    ax.plot(monthly_counts.index, monthly_counts.values, \n",
    "            marker='o', linewidth=2, markersize=8)\n",
    "    ax.set_xlabel('Month', fontsize=11)\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Number of Transactions', fontsize=11)\n",
    "    ax.set_title(f'Transactions in {year}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add total count as text\n",
    "    total_year = year_data.shape[0]\n",
    "    ax.text(0.02, 0.98, f'Total: {total_year:,}', \n",
    "            transform=ax.transAxes, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Yearly Transaction Trends Comparison', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / 'yearly_transaction_trends.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5578d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product sales histograms by year\n",
    "# Group transactions by year and product\n",
    "df['year'] = df['date'].dt.year\n",
    "product_sales_by_year = df.groupby(['year', 'product_id']).size().reset_index(name='transaction_count')\n",
    "\n",
    "# Get unique years\n",
    "years = sorted(df['year'].unique())\n",
    "n_years = len(years)\n",
    "\n",
    "# Create 2x2 grid layout for better legibility\n",
    "n_rows = 2\n",
    "n_cols = 2\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 12))\n",
    "\n",
    "# Flatten axes array for easier indexing\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, year in enumerate(years):\n",
    "    if idx >= n_rows * n_cols:\n",
    "        break  # Only plot up to 4 years in 2x2 grid\n",
    "    \n",
    "    ax = axes_flat[idx]\n",
    "    \n",
    "    # Filter data for this year\n",
    "    year_data = product_sales_by_year[product_sales_by_year['year'] == year]\n",
    "    \n",
    "    # Sort by transaction count (descending) for better visualization\n",
    "    year_data_sorted = year_data.sort_values('transaction_count', ascending=False)\n",
    "    \n",
    "    # Print top 5 and bottom 5 products for this year\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Year {year} - Product Sales Summary\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nTop 5 Products:\")\n",
    "    top_5 = year_data_sorted.head(5)\n",
    "    for rank, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "        print(f\"  {rank}. {row['product_id']:20s} - {row['transaction_count']:6,} transactions\")\n",
    "    \n",
    "    print(\"\\nBottom 5 Products:\")\n",
    "    bottom_5 = year_data_sorted.tail(5)\n",
    "    total_products = len(year_data_sorted)\n",
    "    for idx, (_, row) in enumerate(bottom_5.iterrows()):\n",
    "        rank = total_products - 4 + idx\n",
    "        print(f\"  {rank}. {row['product_id']:20s} - {row['transaction_count']:6,} transactions\")\n",
    "    \n",
    "    # Create horizontal bar chart (histogram-like)\n",
    "    # Each histogram has its own independent y-axis labels (no sharey!)\n",
    "    ax.barh(range(len(year_data_sorted)), year_data_sorted['transaction_count'].values)\n",
    "    ax.set_yticks(range(len(year_data_sorted)))\n",
    "    ax.set_yticklabels(year_data_sorted['product_id'].values, fontsize=7)\n",
    "    ax.set_xlabel('Number of Transactions', fontsize=10)\n",
    "    ax.set_ylabel('Product', fontsize=10)\n",
    "    ax.set_title(f'Product Sales in {year}', fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add total count as text\n",
    "    total_year = year_data['transaction_count'].sum()\n",
    "    ax.text(0.98, 0.02, f'Total: {total_year:,}', \n",
    "            transform=ax.transAxes, verticalalignment='bottom', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "# Hide unused subplots if there are fewer than 4 years\n",
    "for idx in range(n_years, n_rows * n_cols):\n",
    "    axes_flat[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Product Sales Distribution by Year', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / 'product_sales_by_year.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132af6e",
   "metadata": {},
   "source": [
    "### 6.2 Customer Activity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of transactions per customer\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(customer_activity.values, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Number of Transactions per Customer', fontsize=12)\n",
    "ax.set_ylabel('Number of Customers', fontsize=12)\n",
    "ax.set_title('Distribution of Customer Activity', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics\n",
    "ax.axvline(customer_activity.median(), color='red', linestyle='--', linewidth=2, label=f'Median: {customer_activity.median():.1f}')\n",
    "ax.axvline(customer_activity.mean(), color='green', linestyle='--', linewidth=2, label=f'Mean: {customer_activity.mean():.1f}')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / 'customer_activity_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee930562",
   "metadata": {},
   "source": [
    "## 7. Key Observations and Insights\n",
    "\n",
    "Document findings that will inform modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdeca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key statistics for documentation\n",
    "print(\"=== KEY OBSERVATIONS ===\\n\")\n",
    "\n",
    "# Customer heterogeneity\n",
    "print(f\"\\n1. CUSTOMER HETEROGENEITY:\")\n",
    "print(f\"   - Transactions per customer - Mean: {customer_activity.mean():.2f}\")\n",
    "print(f\"   - Transactions per customer - Median: {customer_activity.median():.2f}\")\n",
    "print(f\"   - Transactions per customer - Std: {customer_activity.std():.2f}\")\n",
    "print(f\"   - Coefficient of variation: {customer_activity.std() / customer_activity.mean():.2f}\")\n",
    "print(f\"   - Top 10% of customers account for {customer_activity.nlargest(int(len(customer_activity) * 0.1)).sum() / customer_activity.sum():.1%} of transactions\")\n",
    "\n",
    "# Temporal coverage\n",
    "print(f\"\\n2. TEMPORAL COVERAGE:\")\n",
    "print(f\"   - Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"   - Total days: {(df['date'].max() - df['date'].min()).days}\")\n",
    "print(f\"   - Months with data: {df['year_month'].nunique()}\")\n",
    "\n",
    "# Product distribution\n",
    "print(f\"\\n3. PRODUCT DISTRIBUTION:\")\n",
    "print(f\"   - Number of unique products: {df['product_id'].nunique()}\")\n",
    "print(f\"   - Most popular product: {transactions_per_product.index[0]} ({transactions_per_product.iloc[0]:,} transactions)\")\n",
    "print(f\"   - Least popular product: {transactions_per_product.index[-1]} ({transactions_per_product.iloc[-1]:,} transactions)\")\n",
    "\n",
    "# Seasonality check (preliminary)\n",
    "print(f\"\\n4. SEASONALITY (Preliminary):\")\n",
    "monthly_2018 = df_2018.groupby(df_2018['date'].dt.month).size()\n",
    "if len(monthly_2018) > 0:\n",
    "    print(f\"   - 2018 monthly transaction counts:\")\n",
    "    for month, count in monthly_2018.items():\n",
    "        month_name = pd.Timestamp(2018, month, 1).strftime('%B')\n",
    "        print(f\"     {month_name}: {count:,}\")\n",
    "    # Check for seasonality pattern\n",
    "    if monthly_2018.max() / monthly_2018.min() > 1.5:\n",
    "        print(f\"   - Significant variation detected (max/min ratio: {monthly_2018.max() / monthly_2018.min():.2f})\")\n",
    "    else:\n",
    "        print(f\"   - Relatively stable across months\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d73ef",
   "metadata": {},
   "source": [
    "### Summary for Modeling\n",
    "\n",
    "Based on the exploratory analysis:\n",
    "\n",
    "1. **Data Quality**: Data quality was good overall, very little duplicates which were treated as errors and removed (alternative would've been to consider purchases with quanitity > 1 as having logged over mutiple lines but there were so little it did not matter). Some product_ids were found to be odd and were grouped into one \"Other\" category.\n",
    "2. **Customer Heterogeneity**: Variance is high meaning we need a model where the variance scales stronger than the mean, first consideration of Poisson distribution is therefore not fit.\n",
    "3. **Temporal Patterns**: We can observe in 2017 and 2018 that there are strong peaks of activity towards the middle and end of year (summer and beginning of Winter). This trend does not translate as cleanly in 2019 which seems to show more market stability with smaller variance. Very little data for 2020 with a sharp drop off in sales since the beginning of the year (understandable as it could be heavily justified by the social context at the time --Pandemic--)\n",
    "4. **Product Dynamics**: \n",
    "Dominant products seem to keep up that dominance throughout the entirety of the year, sals in function of product seem to decrease exponentially from best selling to worst selling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d585fa5-6336-492f-8e3e-8a198e63c5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales-forecast (poetry)",
   "language": "python",
   "name": "sales-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
